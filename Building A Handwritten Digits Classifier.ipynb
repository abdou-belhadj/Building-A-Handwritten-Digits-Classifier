{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_digits(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = images[0]\n",
    "target = images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e323ea58e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = data.iloc[0]\n",
    "np_image = first_image.values\n",
    "np_image = np_image.reshape(8,8)\n",
    "\n",
    "plt.imshow(np_image, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e323c8ef40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(2, 4)\n",
    "\n",
    "axarr[0, 0].imshow(data.iloc[0].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 1].imshow(data.iloc[100].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 2].imshow(data.iloc[200].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 3].imshow(data.iloc[300].values.reshape(8,8), cmap='gray_r')\n",
    "\n",
    "axarr[1, 0].imshow(data.iloc[1000].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 1].imshow(data.iloc[1100].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 2].imshow(data.iloc[1200].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 3].imshow(data.iloc[1300].values.reshape(8,8), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_knc(train_data, train_target, k):\n",
    "    knc = KNeighborsClassifier(n_neighbors=k)\n",
    "    knc.fit(train_data, train_target)\n",
    "    return knc\n",
    "\n",
    "def test(test_data, test_target, model):\n",
    "    predictions = model.predict(test_data)\n",
    "    acc = accuracy_score(test_target, predictions)\n",
    "    return acc\n",
    "\n",
    "def cross_validate_knc(k):\n",
    "    accuracies = []\n",
    "    kf = KFold(n_splits = 4, shuffle=True, random_state=1)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data, test_data = data.loc[train_index], data.loc[test_index]\n",
    "        train_target, test_target = target.loc[train_index], target.loc[test_index]\n",
    "        model = train_knc(train_data, train_target, k)\n",
    "        acc = test(test_data, test_target, model)\n",
    "        accuracies.append(acc)\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of 1 is 0.9827456075228903\n",
      "accuracy of 5 is 0.9832999257609502\n",
      "accuracy of 10 is 0.9782887899034892\n"
     ]
    }
   ],
   "source": [
    "neighbors = [1, 5, 10]\n",
    "for k in neighbors:\n",
    "    knc_acc = cross_validate_knc(k)\n",
    "    print('accuracy of {} is {}'.format(k, knc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network With One Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train_mlp(train_data, train_target, neurons):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = neurons)\n",
    "    mlp.fit(train_data, train_target)\n",
    "    return mlp\n",
    "\n",
    "def test(test_data, test_target, model):\n",
    "    predictions = model.predict(test_data)\n",
    "    acc = accuracy_score(test_target, predictions)\n",
    "    return acc\n",
    "\n",
    "def cross_validate_mlp(neurons):\n",
    "    accuracies = []\n",
    "    kf = KFold(n_splits = 4, shuffle=True, random_state=1)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data, test_data = data.loc[train_index], data.loc[test_index]\n",
    "        train_target, test_target = target.loc[train_index], target.loc[test_index]\n",
    "        model = train_mlp(train_data, train_target, neurons)\n",
    "        acc = test(test_data, test_target, model)\n",
    "        accuracies.append(acc)\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (1,) is 0.13246844840386043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (8,) is 0.9315478841870823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (16,) is 0.9521380846325167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abder\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (32,) is 0.9510232615689185\n",
      "accuracy of (64,) is 0.9705011135857461\n",
      "accuracy of (128,) is 0.9682764167285326\n",
      "accuracy of (256,) is 0.9738418708240535\n"
     ]
    }
   ],
   "source": [
    "neurons_list = [(1,) , (8,), (16,), (32,), (64,), (128,), (256,)]\n",
    "\n",
    "for n in neurons_list:\n",
    "    knc_acc = cross_validate_mlp(n)\n",
    "    print('accuracy of {} is {}'.format(n, knc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "It looks like adding more neurons to the single hidden layer helped massively improved simple accuracy from approximately 93% to approximately 97%. Simple accuracy computes the number of correct classifications the model made, but doesn't tell us anything about false or true positives or false or true negatives.\n",
    "\n",
    "Given that k-nearest neighbors achieved approximately 98% accuracy, there doesn't seem to be any advantages to using a single hidden layer neural network for this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network With two Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (64, 64) is 0.9671640682999258\n",
      "accuracy of (128, 128) is 0.9755122494432071\n",
      "accuracy of (256, 256) is 0.9771813907448651\n"
     ]
    }
   ],
   "source": [
    "layers_two_neurons = [(64, 64) , (128, 128), (256, 256)]\n",
    "\n",
    "for l in layers_two_neurons:\n",
    "    knc_acc = cross_validate_mlp(l)\n",
    "    print('accuracy of {} is {}'.format(l, knc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Using 2 hidden layers improved our simple accuracy to approximately 98%. While I'd traditionally be worried about overfitting, using 4-fold cross validation also gives me a bit more assurance that the model is generalizing to achieve the extra 1% in simple accuracy over the single hidden layer networks we tried earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network With Three Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (10, 10, 10) is 0.9343459680416202\n",
      "accuracy of (64, 64, 64) is 0.9732943143812708\n",
      "accuracy of (128, 128, 128) is 0.9799665551839465\n"
     ]
    }
   ],
   "source": [
    "def train_mlp_iter(train_data, train_target, neurons):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = neurons, max_iter=1000)\n",
    "    mlp.fit(train_data, train_target)\n",
    "    return mlp\n",
    "\n",
    "def cross_validate_six(neurons):\n",
    "    accuracies = []\n",
    "    kf = KFold(n_splits = 6, shuffle=True, random_state=1)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data, test_data = data.loc[train_index], data.loc[test_index]\n",
    "        train_target, test_target = target.loc[train_index], target.loc[test_index]\n",
    "        model = train_mlp_iter(train_data, train_target, neurons)\n",
    "        acc = test(test_data, test_target, model)\n",
    "        accuracies.append(acc)\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    return mean_acc\n",
    "\n",
    "layers_three_neurons = [(10, 10, 10) , (64, 64, 64), (128, 128, 128)]\n",
    "\n",
    "for l in layers_three_neurons:\n",
    "    knc_acc = cross_validate_six(l)\n",
    "    print('accuracy of {} is {}'.format(l, knc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Using 3 hidden layers improved our simple accuracy to 98%, even with 6-fold cross validation and 1000 iterations. This seems to be in line with the research literature out there about deep neural networks for computer vision. Having more layers and more neurons tends to improve the network's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network With Three Hidden Layers (Without Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of (10, 10, 10) is 0.8709677419354839\n",
      "accuracy of (64, 64, 64) is 0.9221357063403782\n",
      "accuracy of (128, 128, 128) is 0.9432703003337041\n"
     ]
    }
   ],
   "source": [
    "train_index = round(len(data)/2)\n",
    "train_data = data[:train_index]\n",
    "test_data = data[train_index:]\n",
    "\n",
    "train_target = target[:train_index]\n",
    "test_target = target[train_index:]\n",
    "\n",
    "def train(train_data, train_target, neurons):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = neurons, max_iter=1000)\n",
    "    mlp.fit(train_data, train_target)\n",
    "    return mlp\n",
    "\n",
    "def test(test_data, test_target, model):\n",
    "    predictions = model.predict(test_data)\n",
    "    acc = accuracy_score(test_target, predictions)\n",
    "    return acc\n",
    "\n",
    "def predict_mlp(neurons):\n",
    "    model = train(train_data, train_target, neurons)\n",
    "    acc = test(test_data, test_target, model)\n",
    "    return acc\n",
    "\n",
    "layers_three_neurons = [(10, 10, 10) , (64, 64, 64), (128, 128, 128)]\n",
    "\n",
    "for l in layers_three_neurons:\n",
    "    knc_acc = predict_mlp(l)\n",
    "    print('accuracy of {} is {}'.format(l, knc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Using 3 hidden layers without cross validation reached only 94%, even with 3 hidden layers of 128 neurons and 1000 iterations. \n",
    "\n",
    "# Final \n",
    "\n",
    "Neural Network With Three Hidden Layers (64, 64, 64) and K-Nearest Neighbors Model with (n_neighbors = 5) achieved the best results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
